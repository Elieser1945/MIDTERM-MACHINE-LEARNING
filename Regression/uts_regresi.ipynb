{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySUkh5R35Wj2"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# üìå **Regression Models**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Tujuan notebook ini:\n",
        "- Membangun pipeline regresi end-to-end untuk memprediksi target kontinu dari fitur numerik.\n",
        "- Mencakup: load data, EDA singkat, preprocessing (imputasi, outlier handling, scaling),\n",
        "  train/val split, baseline Linear Regression, RandomForest, XGBoost, hyperparameter tuning,\n",
        "  stacking sederhana, evaluasi akhir, saving model & inference.\n",
        "\n",
        "Dataset:\n",
        "- File: /content/midterm-regresi-dataset.csv\n",
        "- Format: baris pertama = target (kontinu), diikuti ~89 fitur numerik tanpa header.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rIBgfOY5Wj4"
      },
      "source": [
        "# 1. Install & import library\n",
        ">Kode ini memuat berbagai library penting untuk analisis data, visualisasi, dan pemodelan regresi. Pandas dan NumPy digunakan untuk manipulasi data, sedangkan matplotlib dan seaborn untuk visualisasi. Modul scikit-learn disertakan untuk preprocessing, pembagian data, dan penerapan berbagai model regresi seperti Linear, Ridge, Lasso, Random Forest, Gradient Boosting, dan Decision Tree. XGBoost juga ditambahkan sebagai model boosting lanjutan. Berbagai metrik evaluasi diimpor untuk menilai performa model, dan random seed diatur agar hasil dapat direproduksi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRKrhRLB5Wj4"
      },
      "outputs": [],
      "source": [
        "# Data manipulation and analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "\n",
        "# Machine Learning libraries\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Regression models\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Evaluation metrics\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error, r2_score,\n",
        "    mean_absolute_percentage_error\n",
        ")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"‚úì All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q17ryovU5Wj5"
      },
      "source": [
        "# 2. Load Dataset\n",
        ">Kode ini digunakan untuk memuat dataset pelatihan dari file train_transaction.csv dan menampilkan informasi penting tentang isinya. Setelah data dibaca dengan pd.read_csv, program mencetak ukuran dataset, contoh lima baris pertama, statistik deskriptif untuk variabel target TransactionAmt, serta jumlah total nilai yang hilang di seluruh kolom. Langkah ini membantu memahami struktur awal data dan kondisi kualitas dataset sebelum dilakukan proses analisis atau preprocessing lebih lanjut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSyHF2YY5Wj5"
      },
      "outputs": [],
      "source": [
        "# Load the training data\n",
        "train_df = pd.read_csv('datasets/transaction/train_transaction.csv')\n",
        "\n",
        "print(\"Dataset Shape:\", train_df.shape)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"First 5 rows:\")\n",
        "print(train_df.head())\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Target Variable Statistics (TransactionAmt):\")\n",
        "print(train_df['TransactionAmt'].describe())\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Missing Values:\")\n",
        "print(f\"Total missing values: {train_df.isnull().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOmiWGrC5Wj5"
      },
      "source": [
        "# 3. Exploratory Data Analysis (EDA)\n",
        ">Kode ini digunakan untuk memvisualisasikan distribusi nilai TransactionAmt menggunakan tiga jenis grafik: histogram, boxplot, dan histogram versi log-transform. Histogram pertama menunjukkan persebaran nilai transaksi dalam rentang umum, sementara boxplot membantu melihat penyebaran dan potensi outlier. Grafik log-transform digunakan untuk membuat distribusi yang sangat miring menjadi lebih mudah dianalisis. Setelah visualisasi ditampilkan, kode juga mencetak rentang nilai transaksi, rata-rata, dan median untuk memberikan gambaran statistik dasar tentang variabel tersebut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zNCzKLa5Wj5"
      },
      "outputs": [],
      "source": [
        "# Visualize Transaction Amount Distribution\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Histogram\n",
        "axes[0].hist(train_df['TransactionAmt'], bins=100, color='skyblue', edgecolor='black')\n",
        "axes[0].set_title('Transaction Amount Distribution', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Transaction Amount ($)')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].set_xlim(0, 1000)  # Focus on common range\n",
        "\n",
        "# Box plot\n",
        "axes[1].boxplot(train_df['TransactionAmt'], vert=True)\n",
        "axes[1].set_title('Transaction Amount Box Plot', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel('Transaction Amount ($)')\n",
        "axes[1].set_ylim(0, 500)\n",
        "\n",
        "# Log scale distribution\n",
        "axes[2].hist(np.log1p(train_df['TransactionAmt']), bins=100, color='lightcoral', edgecolor='black')\n",
        "axes[2].set_title('Log-Transformed Transaction Amount', fontsize=14, fontweight='bold')\n",
        "axes[2].set_xlabel('Log(Transaction Amount)')\n",
        "axes[2].set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nTransaction Amount Range: ${train_df['TransactionAmt'].min():.2f} - ${train_df['TransactionAmt'].max():.2f}\")\n",
        "print(f\"Mean Transaction Amount: ${train_df['TransactionAmt'].mean():.2f}\")\n",
        "print(f\"Median Transaction Amount: ${train_df['TransactionAmt'].median():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AePyJRpL5Wj5"
      },
      "source": [
        "# 4. Data Preprocessing and Feature Engineering\n",
        ">Kode ini membuat salinan dataset dan menghapus kolom TransactionID serta isFraud karena tugas ini fokus pada regresi, bukan klasifikasi. Setelah itu, hanya fitur-fitur penting yang dipilih, lalu kolom kategorikal diubah menjadi format numerik menggunakan LabelEncoder. Untuk menangani nilai hilang, digunakan SimpleImputer dengan strategi median agar lebih tahan terhadap nilai ekstrem. Selanjutnya, dilakukan pembersihan data dengan menghapus outlier pada kolom TransactionAmt menggunakan metode IQR sehingga model menjadi lebih stabil. Hasil akhirnya adalah dataset yang telah diseleksi, di-encode, diimputasi, dan dibersihkan dari outlier, siap digunakan untuk pelatihan model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LLCPk-f5Wj6"
      },
      "outputs": [],
      "source": [
        "# Create a working copy\n",
        "df = train_df.copy()\n",
        "\n",
        "# Drop TransactionID and isFraud (for regression, we don't use fraud label)\n",
        "df = df.drop(['TransactionID', 'isFraud'], axis=1, errors='ignore')\n",
        "\n",
        "# Select important features for regression\n",
        "important_cols = ['TransactionAmt', 'TransactionDT', 'ProductCD',\n",
        "                  'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
        "                  'addr1', 'addr2', 'dist1', 'dist2',\n",
        "                  'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10',\n",
        "                  'D1', 'D2', 'D3', 'D4', 'D5', 'D10', 'D15',\n",
        "                  'M1', 'M2', 'M3', 'M4',\n",
        "                  'V12', 'V13', 'V20', 'V36', 'V37', 'V45', 'V53', 'V54']\n",
        "\n",
        "# Keep only columns that exist\n",
        "important_cols = [col for col in important_cols if col in df.columns]\n",
        "df = df[important_cols]\n",
        "\n",
        "print(f\"Selected {len(important_cols)} features for modeling\")\n",
        "print(f\"Dataset shape after feature selection: {df.shape}\")\n",
        "\n",
        "# Handle categorical variables\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "if 'TransactionAmt' in categorical_cols:\n",
        "    categorical_cols.remove('TransactionAmt')\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "\n",
        "print(f\"\\n‚úì Categorical variables encoded\")\n",
        "\n",
        "# Handle missing values\n",
        "print(f\"\\nMissing values before imputation: {df.isnull().sum().sum()}\")\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "print(f\"Missing values after imputation: {df_imputed.isnull().sum().sum()}\")\n",
        "\n",
        "# Remove outliers using IQR method (optional - keeps extreme values reasonable)\n",
        "Q1 = df_imputed['TransactionAmt'].quantile(0.25)\n",
        "Q3 = df_imputed['TransactionAmt'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 3 * IQR\n",
        "upper_bound = Q3 + 3 * IQR\n",
        "\n",
        "df_clean = df_imputed[(df_imputed['TransactionAmt'] >= lower_bound) &\n",
        "                      (df_imputed['TransactionAmt'] <= upper_bound)]\n",
        "\n",
        "print(f\"\\nData shape after outlier removal: {df_clean.shape}\")\n",
        "print(f\"Removed {len(df_imputed) - len(df_clean)} outliers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separate features and target\n",
        ">Kode ini memisahkan dataset menjadi fitur (X) dan target (y) dengan menjadikan TransactionAmt sebagai variabel yang ingin diprediksi. Setelah itu, data dibagi menjadi training set dan test set dengan proporsi 80:20 untuk memastikan model dapat diuji secara objektif. Langkah selanjutnya adalah melakukan feature scaling menggunakan StandardScaler agar seluruh fitur berada pada skala yang sama, sehingga model‚Äîterutama yang sensitif terhadap perbedaan skala‚Äîdapat belajar dengan lebih stabil dan efisien. Hasil akhirnya adalah data yang sudah terpisah, terstandardisasi, dan siap digunakan untuk pelatihan model regresi."
      ],
      "metadata": {
        "id": "-q9CRRc99wLh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoG-_I-V5Wj6"
      },
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = df_clean.drop('TransactionAmt', axis=1)\n",
        "y = df_clean['TransactionAmt']\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"Target vector shape: {y.shape}\")\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nTraining set size: {X_train.shape}\")\n",
        "print(f\"Testing set size: {X_test.shape}\")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\n‚úì Data split and scaled successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ln7q6T55Wj6"
      },
      "source": [
        "# 5. Model Training and Evaluation\n",
        ">Kode ini membuat sebuah fungsi untuk melatih dan mengevaluasi model regresi secara menyeluruh. Di dalamnya, model akan dilatih menggunakan data training lalu menghasilkan prediksi untuk data training dan data testing. Fungsi ini menghitung metrik penting seperti R¬≤, RMSE, dan MAE untuk menilai performa model pada kedua subset data. Selain evaluasi numerik, fungsi juga menampilkan dua visualisasi: grafik Predicted vs Actual untuk melihat sejauh mana hasil prediksi mendekati nilai sebenarnya, serta Residual Plot untuk memeriksa pola kesalahan model. Pada akhirnya, fungsi mengembalikan ringkasan performa dalam bentuk dictionary sehingga mudah dianalisis atau dibandingkan antar model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7Kwq9eV5Wj6"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate regression models\n",
        "def evaluate_regression_model(name, model, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Train and evaluate a regression model\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Training {name}...\")\n",
        "    print('='*80)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    train_r2 = r2_score(y_train, y_pred_train)\n",
        "    test_r2 = r2_score(y_test, y_pred_test)\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
        "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
        "\n",
        "    print(f\"\\nüìä Training Performance:\")\n",
        "    print(f\"   R¬≤ Score: {train_r2:.4f}\")\n",
        "    print(f\"   RMSE:     ${train_rmse:.2f}\")\n",
        "    print(f\"   MAE:      ${train_mae:.2f}\")\n",
        "\n",
        "    print(f\"\\nüìä Testing Performance:\")\n",
        "    print(f\"   R¬≤ Score: {test_r2:.4f}\")\n",
        "    print(f\"   RMSE:     ${test_rmse:.2f}\")\n",
        "    print(f\"   MAE:      ${test_mae:.2f}\")\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Predicted vs Actual\n",
        "    axes[0].scatter(y_test, y_pred_test, alpha=0.5, s=10)\n",
        "    axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "    axes[0].set_xlabel('Actual Transaction Amount ($)')\n",
        "    axes[0].set_ylabel('Predicted Transaction Amount ($)')\n",
        "    axes[0].set_title(f'{name} - Predicted vs Actual', fontweight='bold')\n",
        "    axes[0].grid(alpha=0.3)\n",
        "\n",
        "    # Residual plot\n",
        "    residuals = y_test - y_pred_test\n",
        "    axes[1].scatter(y_pred_test, residuals, alpha=0.5, s=10)\n",
        "    axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "    axes[1].set_xlabel('Predicted Transaction Amount ($)')\n",
        "    axes[1].set_ylabel('Residuals ($)')\n",
        "    axes[1].set_title(f'{name} - Residual Plot', fontweight='bold')\n",
        "    axes[1].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'model': name,\n",
        "        'train_r2': train_r2,\n",
        "        'test_r2': test_r2,\n",
        "        'train_rmse': train_rmse,\n",
        "        'test_rmse': test_rmse,\n",
        "        'train_mae': train_mae,\n",
        "        'test_mae': test_mae\n",
        "    }\n",
        "\n",
        "print(\"‚úì Evaluation function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCirsMs45Wj6"
      },
      "source": [
        "# 5.1 Linear Regression\n",
        ">Kode ini melatih model Linear Regression menggunakan data yang telah di-scaling. Model kemudian dievaluasi menggunakan fungsi evaluate_regression_model(), yang menghitung performa model pada data training dan testing serta menampilkan visualisasi prediksi dan residual. Tujuan langkah ini adalah menjadikan Linear Regression sebagai baseline sederhana sebelum dibandingkan dengan model regresi lainnya yang lebih kompleks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3upW1rN5Wj6"
      },
      "outputs": [],
      "source": [
        "# Train Linear Regression\n",
        "lr_model = LinearRegression()\n",
        "lr_results = evaluate_regression_model('Linear Regression', lr_model,\n",
        "                                       X_train_scaled, y_train,\n",
        "                                       X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCIGJgm85Wj7"
      },
      "source": [
        "# 5.2 Ridge Regression (L2 Regularization)\n",
        ">Kode ini menjalankan pelatihan model Ridge Regression, yaitu varian dari regresi linear yang menggunakan regularisasi L2 untuk mencegah overfitting. Parameter alpha=1.0 menentukan seberapa kuat regularisasi diterapkan, sementara random_state=42 memastikan hasil yang konsisten. Model ini kemudian dievaluasi menggunakan fungsi evaluate_regression_model(), yang menghitung metrik performa seperti R¬≤, RMSE, dan MAE, serta menampilkan grafik prediksi dan residual. Ridge Regression biasanya memberikan hasil lebih stabil dibanding Linear Regression, terutama ketika fitur memiliki multikolinearitas atau varians tinggi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-Jq5v1A5Wj7"
      },
      "outputs": [],
      "source": [
        "# Train Ridge Regression\n",
        "ridge_model = Ridge(alpha=1.0, random_state=42)\n",
        "ridge_results = evaluate_regression_model('Ridge Regression', ridge_model,\n",
        "                                         X_train_scaled, y_train,\n",
        "                                         X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u06Gp1lm5Wj7"
      },
      "source": [
        "# 5.3 Lasso Regression (L1 Regularization)\n",
        ">Kode ini melatih model Lasso Regression, yaitu metode regresi linear yang menggunakan regularisasi L1 untuk mengurangi overfitting sekaligus melakukan seleksi fitur secara otomatis. Dengan alpha=0.1, model mengontrol kekuatan penalti sehingga beberapa koefisien dapat dipaksa menjadi nol, membuat model lebih sederhana dan efisien. Parameter max_iter=10000 memastikan proses optimisasi berjalan hingga konvergen. Model kemudian dievaluasi menggunakan fungsi evaluate_regression_model(), yang menghitung metrik seperti R¬≤, RMSE, serta MAE, dan menghasilkan visualisasi prediksi serta residual. Lasso Regression biasanya efektif ketika sejumlah fitur tidak terlalu berpengaruh dan perlu dieliminasi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mm1RRCba5Wj7"
      },
      "outputs": [],
      "source": [
        "# Train Lasso Regression\n",
        "lasso_model = Lasso(alpha=0.1, random_state=42, max_iter=10000)\n",
        "lasso_results = evaluate_regression_model('Lasso Regression', lasso_model,\n",
        "                                         X_train_scaled, y_train,\n",
        "                                         X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtqnHuiM5Wj7"
      },
      "source": [
        "# 5.4 Random Forest Regressor\n",
        ">Kode ini melatih model Random Forest Regressor, yaitu metode ensemble berbasis kumpulan decision tree yang mampu menangkap pola hubungan kompleks dalam data. Parameter seperti n_estimators=100 mengatur jumlah pohon, max_depth=15 membatasi kedalaman pohon untuk mencegah overfitting, dan n_jobs=-1 memungkinkan pemrosesan paralel agar pelatihan lebih cepat. Setelah pelatihan selesai, model dievaluasi menggunakan fungsi evaluate_regression_model(). Selain itu, kode juga menghitung feature importance untuk menunjukkan fitur mana yang paling berpengaruh dalam prediksi. Hasilnya divisualisasikan melalui grafik baris yang menampilkan 15 fitur terpenting, sehingga memudahkan analisis kontribusi tiap variabel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwwUK7Vl5Wj7"
      },
      "outputs": [],
      "source": [
        "# Train Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
        "rf_results = evaluate_regression_model('Random Forest', rf_model,\n",
        "                                      X_train_scaled, y_train,\n",
        "                                      X_test_scaled, y_test)\n",
        "\n",
        "# Feature Importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance.head(15), x='importance', y='feature', palette='viridis')\n",
        "plt.title('Top 15 Most Important Features (Random Forest)', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYR8JXZM5Wj7"
      },
      "source": [
        "# 5.5 Gradient Boosting Regressor\n",
        ">Kode ini melatih model Gradient Boosting Regressor, yaitu algoritma boosting yang membangun pohon keputusan secara bertahap, di mana setiap pohon baru berfungsi memperbaiki kesalahan dari pohon sebelumnya. Parameter n_estimators=100 menentukan jumlah pohon, max_depth=5 mengatur kompleksitas tiap pohon, dan learning_rate=0.1 mengontrol seberapa besar kontribusi setiap pohon baru. Model kemudian dievaluasi menggunakan fungsi evaluate_regression_model(), yang menampilkan metrik performa dan grafik analisis. Gradient Boosting biasanya memberikan performa lebih baik dari metode linear karena mampu menangani hubungan non-linear secara efektif."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K0fOXHl5Wj7"
      },
      "outputs": [],
      "source": [
        "# Train Gradient Boosting Regressor\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
        "gb_results = evaluate_regression_model('Gradient Boosting', gb_model,\n",
        "                                      X_train_scaled, y_train,\n",
        "                                      X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8sI7L4j5Wj7"
      },
      "source": [
        "# 5.6 XGBoost Regressor\n",
        ">Kode ini melatih model XGBoost Regressor, yaitu salah satu algoritma gradient boosting tercepat dan paling efisien yang banyak digunakan untuk kompetisi machine learning. Dengan parameter n_estimators=100, model membangun 100 pohon secara bertahap, sementara max_depth=6 mengatur kedalaman setiap pohon agar model cukup fleksibel tanpa overfitting. Nilai learning_rate=0.1 mengontrol seberapa besar kontribusi tiap pohon baru dalam memperbaiki kesalahan prediksi sebelumnya. Setelah model selesai dilatih, performanya dievaluasi melalui fungsi evaluate_regression_model(), menghasilkan metrik seperti R¬≤, RMSE, MAE, serta visualisasi prediksi dan residual. Model XGBoost sangat efektif dalam menangani pola non-linear dan interaksi antar fitur dengan performa yang stabil dan cepat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UaZuHMb5Wj8"
      },
      "outputs": [],
      "source": [
        "# Train XGBoost Regressor\n",
        "xgb_model = XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)\n",
        "xgb_results = evaluate_regression_model('XGBoost', xgb_model,\n",
        "                                       X_train_scaled, y_train,\n",
        "                                       X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMaWRyuD5Wj8"
      },
      "source": [
        "# 6. Model Comparison and Final Results\n",
        ">Kode ini menyusun seluruh hasil evaluasi dari berbagai model regresi ke dalam satu DataFrame agar performanya mudah dibandingkan. Setelah itu, beberapa grafik dibuat untuk menampilkan perbandingan nilai R¬≤, RMSE, MAE, serta perbandingan R¬≤ antara data training dan testing sebagai indikasi potensi overfitting. Visualisasi ini membantu memahami model mana yang paling akurat dan paling stabil. Selanjutnya, kode secara otomatis memilih model terbaik berdasarkan nilai R¬≤ pada data testing, lalu menampilkan ringkasan performa model tersebut. Dengan cara ini, proses evaluasi menjadi lebih terstruktur, informatif, dan memudahkan pengambilan keputusan terkait model mana yang paling layak digunakan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPvShaV85Wj8"
      },
      "outputs": [],
      "source": [
        "# Compile all results\n",
        "results_df = pd.DataFrame([lr_results, ridge_results, lasso_results,\n",
        "                           rf_results, gb_results, xgb_results])\n",
        "results_df = results_df.round(4)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"MODEL PERFORMANCE COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(results_df.to_string(index=False))\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Visualize model comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# R¬≤ Score Comparison\n",
        "axes[0, 0].bar(results_df['model'], results_df['test_r2'],\n",
        "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8', '#FFD700'])\n",
        "axes[0, 0].set_title('Model R¬≤ Score Comparison (Test Set)', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_ylabel('R¬≤ Score')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "axes[0, 0].set_ylim([0, 1])\n",
        "for i, v in enumerate(results_df['test_r2']):\n",
        "    axes[0, 0].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
        "\n",
        "# RMSE Comparison\n",
        "axes[0, 1].bar(results_df['model'], results_df['test_rmse'],\n",
        "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8', '#FFD700'])\n",
        "axes[0, 1].set_title('Model RMSE Comparison (Test Set)', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_ylabel('RMSE ($)')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "for i, v in enumerate(results_df['test_rmse']):\n",
        "    axes[0, 1].text(i, v + 1, f'${v:.2f}', ha='center', fontweight='bold', fontsize=9)\n",
        "\n",
        "# MAE Comparison\n",
        "axes[1, 0].bar(results_df['model'], results_df['test_mae'],\n",
        "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8', '#FFD700'])\n",
        "axes[1, 0].set_title('Model MAE Comparison (Test Set)', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_ylabel('MAE ($)')\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "for i, v in enumerate(results_df['test_mae']):\n",
        "    axes[1, 0].text(i, v + 0.5, f'${v:.2f}', ha='center', fontweight='bold', fontsize=9)\n",
        "\n",
        "# Train vs Test R¬≤ (Overfitting check)\n",
        "x = np.arange(len(results_df))\n",
        "width = 0.35\n",
        "axes[1, 1].bar(x - width/2, results_df['train_r2'], width, label='Train R¬≤', alpha=0.8)\n",
        "axes[1, 1].bar(x + width/2, results_df['test_r2'], width, label='Test R¬≤', alpha=0.8)\n",
        "axes[1, 1].set_title('Train vs Test R¬≤ Score', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_ylabel('R¬≤ Score')\n",
        "axes[1, 1].set_xticks(x)\n",
        "axes[1, 1].set_xticklabels(results_df['model'], rotation=45, ha='right')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Identify best model\n",
        "best_model_idx = results_df['test_r2'].idxmax()\n",
        "best_model_name = results_df.loc[best_model_idx, 'model']\n",
        "best_r2 = results_df.loc[best_model_idx, 'test_r2']\n",
        "best_rmse = results_df.loc[best_model_idx, 'test_rmse']\n",
        "best_mae = results_df.loc[best_model_idx, 'test_mae']\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üèÜ BEST MODEL SELECTION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Best Model: {best_model_name}\")\n",
        "print(f\"R¬≤ Score: {best_r2:.4f}\")\n",
        "print(f\"RMSE: ${best_rmse:.2f}\")\n",
        "print(f\"MAE: ${best_mae:.2f}\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n‚úÖ Regression model training and evaluation completed successfully!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
